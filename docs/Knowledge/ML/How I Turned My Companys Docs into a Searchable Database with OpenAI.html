<!DOCTYPE html><html><head><title>Codedoc | And how you can do the same with your docs</title><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0"><meta name="robots" content="index,follow"><meta name="theme-color" content="#212121"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><link rel="shortcut icon" href="/codedoc/docs/images/KostweinLogo.ico"><link href="https://fonts.googleapis.com/css?family=Roboto:300,400&amp;display=swap" rel="stylesheet"><link href="https://fonts.googleapis.com/css?family=Source+Code+Pro:300,400&amp;display=swap" rel="stylesheet"><link href="https://fonts.googleapis.com/icon?family=Material+Icons%7CMaterial+Icons+Outlined&amp;display=swap" rel="stylesheet"><style>
      body, input, button {
        font-family: 'Roboto', sans-serif;
      }

      code, .hljs {
        font-family: 'Source Code Pro', 'Courier New', Courier, monospace;
      }

      .icon-font {
        font-family: 'Material Icons';
        font-weight: normal;
        font-style: normal;
        font-size: 24px;  /* Preferred icon size */
        display: inline-block;
        line-height: 1;
        text-transform: none;
        letter-spacing: normal;
        word-wrap: normal;
        white-space: nowrap;
        direction: ltr;
      
        /* Support for all WebKit browsers. */
        -webkit-font-smoothing: antialiased;
        /* Support for Safari and Chrome. */
        text-rendering: optimizeLegibility;
      
        /* Support for Firefox. */
        -moz-osx-font-smoothing: grayscale;
      
        /* Support for IE. */
        font-feature-settings: 'liga';
      }

      .icon-font.outline {
        font-family: 'Material Icons Outlined';
      }
    </style><link href="/codedoc/docs/assets/codedoc-styles.css" rel="stylesheet"><script async="" defer="" src="/codedoc/docs/assets/codedoc-bundle.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous"></head><body data-path="docs\Knowledge\ML\How I Turned My Companys Docs into a Searchable Database with OpenAI.md"><div class="header-0-0-12"><script async="" defer="" src="https://buttons.github.io/buttons.js"></script><a class="github-button" data-color-scheme="no-preference: light; light: light; dark: dark;" data-icon="false" data-show-count="true" data-size="false" href="https://github.com/In-Pro-Org/codedoc/">Star</a><br><br><a class="watermark-0-0-11" href="https://github.com/CONNECT-platform/codedoc" target="_blank">Created With<svg viewBox="0 0 536 296" version="1.1" xmlns="http://www.w3.org/2000/svg"><g id="codedoc" transform="translate(-244.000000, -364.000000)" fill-rule="nonzero"><path d="M580,532 C615.346224,532 644,560.653776 644,596 C644,631.346224 615.346224,660 580,660 C544.653776,660 516,631.346224 516,596 C516,560.653776 544.653776,532 580,532 Z M716,532 C751.346224,532 780,560.653776 780,596 C780,631.346224 751.346224,660 716,660 L692,660 C687.581722,660 684,656.418278 684,652 C684,647.581722 687.581722,644 692,644 L716,644 C742.509668,644 764,622.509668 764,596 C764,569.490332 742.509668,548 716,548 L692,548 C687.581722,548 684,544.418278 684,540 C684,535.581722 687.581722,532 692,532 L716,532 Z M468,532 C472.418278,532 476,535.581722 476,540 L476,652 C476,656.418278 472.418278,660 468,660 L444,660 C408.653776,660 380,631.346224 380,596 C380,560.653776 408.653776,532 444,532 L468,532 Z M332,532 C336.418278,532 340,535.581722 340,540 L340,652 C340,656.418278 336.418278,660 332,660 L252,660 C247.581722,660 244,656.418278 244,652 L244,540 C244,535.581722 247.581722,532 252,532 L332,532 Z M580,548 C553.490332,548 532,569.490332 532,596 C532,622.509668 553.490332,644 580,644 C606.509668,644 628,622.509668 628,596 C628,569.490332 606.509668,548 580,548 Z M461,548 L444,548 C417.490332,548 396,569.490332 396,596 C396,622.509668 417.490332,644 444,644 L461,644 L461,548 Z M444,364 C479.346224,364 508,392.653776 508,428 C508,463.346224 479.346224,492 444,492 C408.653776,492 380,463.346224 380,428 C380,392.653776 408.653776,364 444,364 Z M332,364 C336.418278,364 340,367.581722 340,372 C340,376.418278 336.418278,380 332,380 L308,380 C281.490332,380 260,401.490332 260,428 C260,454.509668 281.490332,476 308,476 L332,476 C336.418278,476 340,479.581722 340,484 C340,488.418278 336.418278,492 332,492 L308,492 C272.653776,492 244,463.346224 244,428 C244,392.653776 272.653776,364 308,364 L332,364 Z M580,364 C615.346224,364 644,392.653776 644,428 C644,463.346224 615.346224,492 580,492 L556,492 C551.581722,492 548,488.418278 548,484 L548,372 C548,367.581722 551.581722,364 556,364 L580,364 Z M772,364 C776.418278,364 780,367.581722 780,372 C780,376.418278 776.418278,380 772,380 L700,380 L700,420 L772,420 C776.418278,420 780,423.581722 780,428 C780,432.418278 776.418278,436 772,436 L700,436 L700,476 L772,476 C776.418278,476 780,479.581722 780,484 C780,488.418278 776.418278,492 772,492 L692,492 C687.581722,492 684,488.418278 684,484 L684,372 C684,367.581722 687.581722,364 692,364 L772,364 Z M444,380 C417.490332,380 396,401.490332 396,428 C396,454.509668 417.490332,476 444,476 C470.509668,476 492,454.509668 492,428 C492,401.490332 470.509668,380 444,380 Z M580,380 L563,380 L563,476 L580,476 C606.509668,476 628,454.509668 628,428 C628,401.490332 606.509668,380 580,380 Z"></path></g></svg></a></div><div id="-codedoc-container" class="container"><h2 id="and-how-you-can-do-the-same-with-your-docs" class="heading-0-0-1"><span class="anchor-0-0-2" data-ignore-text=""><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span>And how you can do the same with your docs</h2><p>[</p><p><img src="https://miro.medium.com/v2/resize:fill:88:88/0*YukZswf8UB1bQdTV" alt="Jacob Marks, Ph.D."></p><p>]<a href="https://medium.com/@jacob_marks?source=post_page-----4f2d34bd8736--------------------------------">1</a>[</p><p><img src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg" alt="Towards Data Science"></p><p>]<a href="https://towardsdatascience.com/?source=post_page-----4f2d34bd8736--------------------------------">2</a></p><p><img src="https://miro.medium.com/v2/resize:fit:700/1*rsp22rKwFDjiwwCcUly56Q.jpeg" alt=""></p><p>Image courtesy of Unsplash.</p><p>For the past six months, I’ve been working at series A startup Voxel51, a and creator of the <a href="https://github.com/voxel51/fiftyone">open source computer vision toolkit FiftyOne</a>. As a machine learning engineer and developer evangelist, my job is to listen to our open source community and bring them what they need — new features, integrations, tutorials, workshops, you name it.</p><p>A few weeks ago, we added native support for vector search engines and text similarity queries to FiftyOne, so that users can find the most relevant images in their (often massive — containing millions or tens of millions of samples) datasets, via simple natural language queries.</p><p>This put us in a curious position: it was now possible for people using open source FiftyOne to readily search datasets with natural language queries, but using our documentation still required traditional keyword search.</p><p>We have a lot of documentation, which has its pros and cons. As a user myself, I sometimes find that given the sheer quantity of documentation, finding precisely what I’m looking for requires more time than I’d like.</p><p>I was not going to let this fly… so I built this in my spare time:</p><p><img src="https://miro.medium.com/v2/resize:fit:700/1*BhZ7mT-Y_RvFhdeSCR6-zQ.gif" alt=""></p><p>Semantically search your company’s docs from the command line. Image courtesy of author.</p><p>So, here’s how I turned our docs into a semantically searchable vector database:</p><ul><li><a href="https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736#eb87">Converted all of the docs to a unified format</a></li><li><a href="https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736#8ed1">Split docs into blocks and added some automated cleanup</a></li><li><a href="https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736#1a17">Computed embeddings for each block</a></li><li><a href="https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736#34d3">Generated a vector index from these embedding</a></li><li><a href="https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736#87c5">Defined the index query</a></li><li><a href="https://towardsdatascience.com/how-i-turned-my-companys-docs-into-a-searchable-database-with-openai-4f2d34bd8736#9d79">Wrapped it all in a user-friendly command line interface and Python API</a></li></ul><p>You can find all the code for this post in the <a href="https://github.com/voxel51/fiftyone-docs-search">voxel51/fiftyone-docs-search</a> repo, and it’s easy to install the package locally in edit mode with <code>pip install -e .</code>.</p><p>Better yet, if you want to implement semantic search for your own website using this method, you can follow along! Here are the ingredients you’ll need:</p><ul><li><em>Install the</em> <a href="https://github.com/openai/openai-python"><em>openai</em></a> <em>Python package and create an account:</em> you will use this account to send your docs and queries to an inference endpoint, which will return an embedding vector for each piece of text.</li><li><em>Install the</em> <a href="https://github.com/qdrant/qdrant_client"><em>qdrant-client</em></a> <em>Python package and launch a</em> <a href="https://qdrant.tech/"><em>Qdrant server via Docker</em></a>: you will use <a href="https://qdrant.tech/">Qdrant</a> to create a locally hosted vector index for the docs, against which queries will be run. The Qdrant service will run inside a Docker container.</li></ul><h2 id="converting-the-docs-to-a-unified-format" class="heading-0-0-1"><span class="anchor-0-0-2" data-ignore-text=""><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span>Converting the docs to a unified format</h2><p>My company’s docs are all hosted as HTML documents at <a href="https://docs.voxel51.com/">https://docs.voxel51.com</a>. A natural starting point would have been to download these docs with Python’s <a href="https://pypi.org/project/requests/">requests</a> library and parse the document with <a href="https://beautiful-soup-4.readthedocs.io/en/latest/">Beautiful Soup</a>.</p><p>As a developer (and author of many of our docs), however, I thought I could do better. I already had a working clone of the GitHub repository on my local computer that contained all of the raw files used to generate the HTML docs. Some of our docs are written in <a href="https://www.sphinx-doc.org/en/master/">Sphinx ReStructured Text (RST)</a>, whereas others, like tutorials, are converted to HTML from Jupyter notebooks.</p><p>I figured (mistakenly) that the closer I could get to the raw text of the RST and Jupyter files, the simpler things would be.</p><h2 id="rst" class="heading-0-0-1"><span class="anchor-0-0-2" data-ignore-text=""><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span>RST</h2><p>In RST documents, sections are delineated by lines consisting only of strings of <code>=</code>, <code>-</code> or <code>_</code>. For example, here’s a document from the FiftyOne User Guide which contains all three delineators:</p><p><img src="https://miro.medium.com/v2/resize:fit:700/1*4IavnXBTTQNrM813sGzq8w.png" alt=""></p><p>RST document from open source FiftyOne Docs. Image courtesy of author.</p><p>I could then remove all of the RST keywords, such as <code>toctree</code>, <code>code-block</code>, and <code>button_link</code> (there were many more), as well as the <code>:</code>, <code>::</code>, and <code>..</code> that accompanied a keyword, the start of a new block, or block descriptors.</p><p>Links were easy to take care of too:</p><pre class=""><code class="undefined -codedoc-code-snippet code-0-0-3" tabindex="0"><span class="wmbar-0-0-8"><span></span><span></span><span></span><span></span></span><div class="line-0-0-7  -codedoc-code-line" data-content="no_links_section = re.sub(r&quot;<[^>]+>_?&quot;,&quot;&quot;, section)" id="code1-l1"><span class="lineCounter-0-0-4 prim -codedoc-line-counter">1<span class="-codedoc-line-link"><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span></span>no_links_section = re.sub(r"&lt;[^&gt;]+&gt;_?","", section)</div><br></code></pre><p>Things started to get dicey when I wanted to extract the section anchors from RST files. Many of our sections had anchors specified explicitly, whereas others were left to be inferred during the conversion to HTML.</p><p>Here is an example:</p><pre class=""><code class="undefined -codedoc-code-snippet code-0-0-3" tabindex="0"><span class="wmbar-0-0-8"><span></span><span></span><span></span><span></span></span><div class="line-0-0-7  -codedoc-code-line" data-content=".. _brain-embeddings-visualization:Visualizing embeddings______________________The FiftyOne Brain provides a powerful:meth:`compute_visualization() <fiftyone.brain.compute_visualization>` methodthat you can use to generate low-dimensional representations of the samplesand/or individual objects in your datasets.These representations can be visualized natively in the App's:ref:`Embeddings panel <app-embeddings-panel>`, where you can interactivelyselect points of interest and view the corresponding samples/labels of interestin the :ref:`Samples panel <app-samples-panel>`, and vice versa... image:: /images/brain/brain-mnist.png   :alt: mnist   :align: centerThere are two primary components to an embedding visualization: the method usedto generate the embeddings, and the dimensionality reduction method used tocompute a low-dimensional representation of the embeddings.Embedding methods-----------------The `embeddings` and `model` parameters of:meth:`compute_visualization() <fiftyone.brain.compute_visualization>`support a variety of ways to generate embeddings for your data:" id="code2-l1"><span class="lineCounter-0-0-4 prim -codedoc-line-counter">1<span class="-codedoc-line-link"><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span></span>.. _brain-embeddings-visualization:Visualizing embeddings______________________The FiftyOne Brain provides a powerful:meth:`compute_visualization() <fiftyone.brain.compute_visualization>` methodthat you can use to generate low-dimensional representations of the samplesand/or individual objects in your datasets.These representations can be visualized natively in the App's:ref:`Embeddings panel <app-embeddings-panel>`, where you can interactivelyselect points of interest and view the corresponding samples/labels of interestin the :ref:`Samples panel <app-samples-panel>`, and vice versa... image:: /images/brain/brain-mnist.png   :alt: mnist   :align: centerThere are two primary components to an embedding visualization: the method usedto generate the embeddings, and the dimensionality reduction method used tocompute a low-dimensional representation of the embeddings.Embedding methods-----------------The `embeddings` and `model` parameters of:meth:`compute_visualization() <fiftyone.brain.compute_visualization>`support a variety of ways to generate embeddings for your data:</fiftyone.brain.compute_visualization></app-samples-panel></app-embeddings-panel></fiftyone.brain.compute_visualization></div><br></code></pre><p>In the brain.rst file in our User Guide docs (a portion of which is reproduced above), the <em>Visualizing embeddings</em> section has an anchor <code>#brain-embeddings-visualization</code> specified by <code>.. _brain-embeddings-visualization:</code>. The <em>Embedding methods</em> subsection which immediately follows, however, is given an auto-generated anchor.</p><p>Another difficulty that soon reared its head was how to deal with tables in RST. <a href="https://sublime-and-sphinx-guide.readthedocs.io/en/latest/tables.html#list-table-directive">List tables</a> were fairly straightforward. For instance, here’s a list table from our View Stages cheat sheet:</p><pre class=""><code class="undefined -codedoc-code-snippet code-0-0-3" tabindex="0"><span class="wmbar-0-0-8"><span></span><span></span><span></span><span></span></span><div class="line-0-0-7  -codedoc-code-line" data-content=".. list-table::   * - :meth:`match() <fiftyone.core.collections.SampleCollection.match>`   * - :meth:`match_frames() <fiftyone.core.collections.SampleCollection.match_frames>`   * - :meth:`match_labels() <fiftyone.core.collections.SampleCollection.match_labels>`   * - :meth:`match_tags() <fiftyone.core.collections.SampleCollection.match_tags>`" id="code3-l1"><span class="lineCounter-0-0-4 prim -codedoc-line-counter">1<span class="-codedoc-line-link"><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span></span>.. list-table::   * - :meth:`match() <fiftyone.core.collections.samplecollection.match>`   * - :meth:`match_frames() <fiftyone.core.collections.samplecollection.match_frames>`   * - :meth:`match_labels() <fiftyone.core.collections.samplecollection.match_labels>`   * - :meth:`match_tags() <fiftyone.core.collections.samplecollection.match_tags>`</fiftyone.core.collections.samplecollection.match_tags></fiftyone.core.collections.samplecollection.match_labels></fiftyone.core.collections.samplecollection.match_frames></fiftyone.core.collections.samplecollection.match></div><br></code></pre><p><a href="https://docutils.sourceforge.io/docs/ref/rst/restructuredtext.html#grid-tables">Grid tables</a>, on the other hand, can get messy fast. They give docs writers great flexibility, but this same flexibility makes parsing them a pain. Take this table from our Filtering cheat sheet:</p><pre class=""><code class="undefined -codedoc-code-snippet code-0-0-3" tabindex="0"><span class="wmbar-0-0-8"><span></span><span></span><span></span><span></span></span><div class="line-0-0-7  -codedoc-code-line" data-content="+-----------------------------------------+-----------------------------------------------------------------------+| Operation                               | Command                                                               |+=========================================+=======================================================================+| Filepath starts with &quot;/Users&quot;           |  .. code-block::                                                      ||                                         |                                                                       ||                                         |     ds.match(F(&quot;filepath&quot;).starts_with(&quot;/Users&quot;))                     |+-----------------------------------------+-----------------------------------------------------------------------+| Filepath ends with &quot;10.jpg&quot; or &quot;10.png&quot; |  .. code-block::                                                      ||                                         |                                                                       ||                                         |     ds.match(F(&quot;filepath&quot;).ends_with((&quot;10.jpg&quot;, &quot;10.png&quot;))            |+-----------------------------------------+-----------------------------------------------------------------------+| Label contains string &quot;be&quot;              |  .. code-block::                                                      ||                                         |                                                                       ||                                         |     ds.filter_labels(                                                 ||                                         |         &quot;predictions&quot;,                                                ||                                         |         F(&quot;label&quot;).contains_str(&quot;be&quot;),                                ||                                         |     )                                                                 |+-----------------------------------------+-----------------------------------------------------------------------+| Filepath contains &quot;088&quot; and is JPEG     |  .. code-block::                                                      ||                                         |                                                                       ||                                         |     ds.match(F(&quot;filepath&quot;).re_match(&quot;088*.jpg&quot;))                      |+-----------------------------------------+-----------------------------------------------------------------------+" id="code4-l1"><span class="lineCounter-0-0-4 prim -codedoc-line-counter">1<span class="-codedoc-line-link"><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span></span>+-----------------------------------------+-----------------------------------------------------------------------+| Operation                               | Command                                                               |+=========================================+=======================================================================+| Filepath starts with "/Users"           |  .. code-block::                                                      ||                                         |                                                                       ||                                         |     ds.match(F("filepath").starts_with("/Users"))                     |+-----------------------------------------+-----------------------------------------------------------------------+| Filepath ends with "10.jpg" or "10.png" |  .. code-block::                                                      ||                                         |                                                                       ||                                         |     ds.match(F("filepath").ends_with(("10.jpg", "10.png"))            |+-----------------------------------------+-----------------------------------------------------------------------+| Label contains string "be"              |  .. code-block::                                                      ||                                         |                                                                       ||                                         |     ds.filter_labels(                                                 ||                                         |         "predictions",                                                ||                                         |         F("label").contains_str("be"),                                ||                                         |     )                                                                 |+-----------------------------------------+-----------------------------------------------------------------------+| Filepath contains "088" and is JPEG     |  .. code-block::                                                      ||                                         |                                                                       ||                                         |     ds.match(F("filepath").re_match("088*.jpg"))                      |+-----------------------------------------+-----------------------------------------------------------------------+</div><br></code></pre><p>Within a table, rows can take up arbitrary numbers of lines, and columns can vary in width. Code blocks within grid table cells are also difficult to parse, as they occupy space on multiple lines, so their content is interspersed with content from other columns. This means that code blocks in these tables need to be effectively reconstructed during the parsing process.</p><p>Not the end of the world. But also not ideal.</p><h2 id="jupyter" class="heading-0-0-1"><span class="anchor-0-0-2" data-ignore-text=""><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span>Jupyter</h2><p>Jupyter notebooks turned out to be relatively simple to parse. I was able to read the contents of a Jupyter notebook into a list of strings, with one string per cell:</p><pre class=""><code class="undefined -codedoc-code-snippet code-0-0-3" tabindex="0"><span class="wmbar-0-0-8"><span></span><span></span><span></span><span></span></span><div class="line-0-0-7  -codedoc-code-line" data-content="import jsonifile = &quot;my_notebook.ipynb&quot;with open(ifile, &quot;r&quot;) as f:    contents = f.read()contents = json.loads(contents)[&quot;cells&quot;]contents = [(&quot; &quot;.join(c[&quot;source&quot;]), c['cell_type'] for c in contents]" id="code5-l1"><span class="lineCounter-0-0-4 prim -codedoc-line-counter">1<span class="-codedoc-line-link"><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span></span>import jsonifile = "my_notebook.ipynb"with open(ifile, "r") as f:    contents = f.read()contents = json.loads(contents)["cells"]contents = [(" ".join(c["source"]), c['cell_type'] for c in contents]</div><br></code></pre><p>Furthermore, the sections were delineated by Markdown cells starting with <code>#</code>.</p><p>Nevertheless, given the challenges posed by RST, I decided to turn to HTML and treat all of our docs on equal footing.</p><h2 id="html" class="heading-0-0-1"><span class="anchor-0-0-2" data-ignore-text=""><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span>HTML</h2><p>I built the HTML docs from my local install with <code>bash generate_docs.bash</code>, and began parsing them with Beautiful Soup. However, I soon realized that when RST code blocks and tables with inline code were being converted to HTML, although they were rendering correctly, the HTML itself was incredibly unwieldy. Take our filtering cheat sheet for example.</p><p>When rendered in a browser, the code block preceding the <em>Dates and times</em> section of our filtering cheat sheet looks like this:</p><p><img src="https://miro.medium.com/v2/resize:fit:700/1*qQbA0hfzNLkDs7vL2L6IDQ.png" alt=""></p><p>Screenshot from cheat sheet in open source FiftyOne Docs. Image courtesy of author.</p><p>The raw HTML, however, looks like this:</p><p><img src="https://miro.medium.com/v2/resize:fit:700/1*Win6Z82ZfGMz0ofsWs9XTQ.png" alt=""></p><p>RST cheat sheet converted to HTML. Image courtesy of author.</p><p>This is not impossible to parse, but it is also far from ideal.</p><h2 id="markdown" class="heading-0-0-1"><span class="anchor-0-0-2" data-ignore-text=""><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span>Markdown</h2><p>Fortunately, I was able to overcome these issues by converting all of the HTML files to Markdown with <a href="https://pypi.org/project/markdownify/">markdownify</a>. Markdown had a few key advantages that made it the best fit for this job.</p><ol><li><strong>Cleaner than HTML</strong>: code formatting was simplified from the spaghetti strings of <code>span</code> elements to inline code snippets marked with single <code>`</code> before and after, and blocks of code were marked by triple quotes <code>```</code>before and after. This also made it easy to split into text and code.</li><li><strong>Still contained anchors:</strong> unlike raw RST, this Markdown included section heading anchors, as the implicit anchors had already been generated. This way, I could link not just to the page containing the result, but to the specific section or subsection of that page.</li><li><strong>Standardization</strong>: Markdown provided a mostly uniform formatting for the initial RST and Jupyter documents, allowing us to give their content consistent treatment in the vector search application.</li></ol><h2 id="note-on-langchain" class="heading-0-0-1"><span class="anchor-0-0-2" data-ignore-text=""><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span>Note on LangChain</h2><p>Some of you may know about the open source library <a href="https://python.langchain.com/en/latest/index.html">LangChain</a> for building applications with LLMs, and may be wondering why I didn’t just use LangChain’s <a href="https://python.langchain.com/en/latest/modules/indexes/document_loaders.html">Document Loaders</a> and <a href="https://python.langchain.com/en/latest/modules/indexes/text_splitters.html">Text Splitters</a>. The answer: I needed more control!</p><h2 id="processing-the-documents" class="heading-0-0-1"><span class="anchor-0-0-2" data-ignore-text=""><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span>Processing the documents</h2><p>Once the documents had been converted to Markdown, I proceeded to clean the contents and split them into smaller segments.</p><h2 id="cleaning" class="heading-0-0-1"><span class="anchor-0-0-2" data-ignore-text=""><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span>Cleaning</h2><p>Cleaning most consisting in removing unnecessary elements, including:</p><ul><li>Headers and footers</li><li>Table row and column scaffolding — e.g. the <code>|</code>’s in <code>|select()| select_by()|</code></li><li>Extra newlines</li><li>Links</li><li>Images</li><li>Unicode characters</li><li>Bolding — i.e. <code>**text**</code> → <code>text</code></li></ul><p>I also removed escape characters that were escaping from characters which have special meaning in our docs: <code>_</code> and <code>*</code>. The former is used in many method names, and the latter, as usual, is used in multiplication, regex patterns, and many other places:</p><pre class=""><code class="undefined -codedoc-code-snippet code-0-0-3" tabindex="0"><span class="wmbar-0-0-8"><span></span><span></span><span></span><span></span></span><div class="line-0-0-7  -codedoc-code-line" data-content="document = document.replace(&quot;\_&quot;, &quot;_&quot;).replace(&quot;\*&quot;, &quot;*&quot;)" id="code6-l1"><span class="lineCounter-0-0-4 prim -codedoc-line-counter">1<span class="-codedoc-line-link"><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span></span>document = document.replace("\_", "_").replace("\*", "*")</div><br></code></pre><h2 id="splitting-documents-into-semantic-blocks" class="heading-0-0-1"><span class="anchor-0-0-2" data-ignore-text=""><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span>Splitting documents into semantic blocks</h2><p>With the contents of our docs cleaned, I proceeded to split the docs into bite-sized blocks.</p><p>First, I split each document into sections. At first glance, it seems like this can be done by finding any line that starts with a <code>#</code> character. In my application, I did not differentiate between h1, h2, h3, and so on (<code>#</code> , <code>##</code> , <code>###</code>), so checking the first character is sufficient. However, this logic gets us in trouble when we realize that <code>#</code> is also employed to allow comments in Python code.</p><p>To bypass this problem, I split the document into text blocks and code blocks:</p><pre class=""><code class="undefined -codedoc-code-snippet code-0-0-3" tabindex="0"><span class="wmbar-0-0-8"><span></span><span></span><span></span><span></span></span><div class="line-0-0-7  -codedoc-code-line" data-content="text_and_code = page_md.split('```')text = text_and_code[::2]code = text_and_code[1::2]" id="code7-l1"><span class="lineCounter-0-0-4 prim -codedoc-line-counter">1<span class="-codedoc-line-link"><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span></span>text_and_code = page_md.split('```')text = text_and_code[::2]code = text_and_code[1::2]</div><br></code></pre><p>Then I identified the start of a new section with a <code>#</code> to start a line in a text block. I extracted the section title and anchor from this line:</p><pre class=""><code class="undefined -codedoc-code-snippet code-0-0-3" tabindex="0"><span class="wmbar-0-0-8"><span></span><span></span><span></span><span></span></span><div class="line-0-0-7  -codedoc-code-line" data-content="def extract_title_and_anchor(header):    header = &quot; &quot;.join(header.split(&quot; &quot;)[1:])    title = header.split(&quot;[&quot;)[0]    anchor = header.split(&quot;(&quot;)[1].split(&quot; &quot;)[0]    return title, anchor" id="code8-l1"><span class="lineCounter-0-0-4 prim -codedoc-line-counter">1<span class="-codedoc-line-link"><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span></span>def extract_title_and_anchor(header):    header = " ".join(header.split(" ")[1:])    title = header.split("[")[0]    anchor = header.split("(")[1].split(" ")[0]    return title, anchor</div><br></code></pre><p>And assigned each block of text or code to the appropriate section.</p><p>Initially, I also tried splitting the text blocks into paragraphs, hypothesizing that because a section may contain information about many different topics, the embedding for that entire section may not be similar to an embedding for a text prompt concerned with only one of those topics. This approach, however, resulted in top matches for most search queries disproportionately being single line paragraphs, which turned out to not be terribly informative as search results.</p><blockquote><p><em>Check out the accompanying</em> <a href="https://github.com/voxel51/fiftyone-docs-search"><em>GitHub repo</em></a> <em>for the implementation of these methods that you can try out on your own docs!</em></p></blockquote><h2 id="embedding-text-and-code-blocks-with-openai" class="heading-0-0-1"><span class="anchor-0-0-2" data-ignore-text=""><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span>Embedding text and code blocks with OpenAI</h2><p>With documents converted, processed, and split into strings, I generated an embedding vector for each of these blocks. Because large language models are flexible and generally capable by nature, I decided to treat both text blocks and code blocks on the same footing as pieces of text, and to embed them with the same model.</p><p>I used OpenAI’s <a href="https://platform.openai.com/docs/guides/embeddings/embedding-models">text-embedding-ada-002 model</a> because it is easy to work with, achieves the highest performance out of all of OpenAI’s embedding models (on the <a href="https://arxiv.org/pdf/2104.08663.pdf">BEIR benchmark</a>), and is also the cheapest. It’s so cheap in fact ($0.0004/1K tokens) that generating all of the embeddings for the FiftyOne docs only cost a few cents! As OpenAI themselves put it, “We recommend using text-embedding-ada-002 for nearly all use cases. It’s better, cheaper, and simpler to use.”</p><p>With this embedding model, you can generate a 1536-dimensional vector representing any input prompt, up to 8,191 tokens (approximately 30,000 characters).</p><p>To get started, you need to create an OpenAI account, generate an API key at <a href="https://platform.openai.com/account/api-keys">https://platform.openai.com/account/api-keys</a>, export this API key as an environment variable with:</p><pre class=""><code class="undefined -codedoc-code-snippet code-0-0-3" tabindex="0"><span class="wmbar-0-0-8"><span></span><span></span><span></span><span></span></span><div class="line-0-0-7  -codedoc-code-line" data-content="export OPENAI_API_KEY=&quot;<MY_API_KEY>&quot;" id="code9-l1"><span class="lineCounter-0-0-4 prim -codedoc-line-counter">1<span class="-codedoc-line-link"><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span></span>export OPENAI_API_KEY="<my_api_key>"</my_api_key></div><br></code></pre><p>You will also need to install the <a href="https://github.com/openai/openai-python">openai Python library</a>:</p><pre class=""><code class="undefined -codedoc-code-snippet code-0-0-3" tabindex="0"><span class="wmbar-0-0-8"><span></span><span></span><span></span><span></span></span><div class="line-0-0-7  -codedoc-code-line" data-content="pip install openai" id="code10-l1"><span class="lineCounter-0-0-4 prim -codedoc-line-counter">1<span class="-codedoc-line-link"><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span></span>pip install openai</div><br></code></pre><p>I wrote a wrapper around OpenAI’s API that takes in a text prompt and returns an embedding vector:</p><pre class=""><code class="undefined -codedoc-code-snippet code-0-0-3" tabindex="0"><span class="wmbar-0-0-8"><span></span><span></span><span></span><span></span></span><div class="line-0-0-7  -codedoc-code-line" data-content="MODEL = &quot;text-embedding-ada-002&quot;def embed_text(text):    response = openai.Embedding.create(        input=text,        model=MODEL    )    embeddings = response['data'][0]['embedding']    return embeddings" id="code11-l1"><span class="lineCounter-0-0-4 prim -codedoc-line-counter">1<span class="-codedoc-line-link"><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span></span>MODEL = "text-embedding-ada-002"def embed_text(text):    response = openai.Embedding.create(        input=text,        model=MODEL    )    embeddings = response['data'][0]['embedding']    return embeddings</div><br></code></pre><p>To generate embeddings for all of our docs, we just apply this function to each of the subsections — text and code blocks — across all of our docs.</p><h2 id="creating-a-qdrant-vector-index" class="heading-0-0-1"><span class="anchor-0-0-2" data-ignore-text=""><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span>Creating a Qdrant vector index</h2><p>With embeddings in hand, I created a vector index to search against. I chose to use Qdrant for the same reasons we chose to add native Qdrant support to FiftyOne: it’s open source, free, and easy to use.</p><p>To get started with Qdrant, you can pull a pre-built Docker image and run the container:</p><pre class=""><code class="undefined -codedoc-code-snippet code-0-0-3" tabindex="0"><span class="wmbar-0-0-8"><span></span><span></span><span></span><span></span></span><div class="line-0-0-7  -codedoc-code-line" data-content="docker pull qdrant/qdrantdocker run -d -p 6333:6333 qdrant/qdrant" id="code12-l1"><span class="lineCounter-0-0-4 prim -codedoc-line-counter">1<span class="-codedoc-line-link"><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span></span>docker pull qdrant/qdrantdocker run -d -p 6333:6333 qdrant/qdrant</div><br></code></pre><p>Additionally, you will need to install the Qdrant Python client:</p><pre class=""><code class="undefined -codedoc-code-snippet code-0-0-3" tabindex="0"><span class="wmbar-0-0-8"><span></span><span></span><span></span><span></span></span><div class="line-0-0-7  -codedoc-code-line" data-content="pip install qdrant-client" id="code13-l1"><span class="lineCounter-0-0-4 prim -codedoc-line-counter">1<span class="-codedoc-line-link"><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span></span>pip install qdrant-client</div><br></code></pre><p>I created the Qdrant collection:</p><pre class=""><code class="undefined -codedoc-code-snippet code-0-0-3" tabindex="0"><span class="wmbar-0-0-8"><span></span><span></span><span></span><span></span></span><div class="line-0-0-7  -codedoc-code-line" data-content="import qdrant_client as qcimport qdrant_client.http.models as qmodelsclient = qc.QdrantClient(url=&quot;localhost&quot;)METRIC = qmodels.Distance.DOTDIMENSION = 1536COLLECTION_NAME = &quot;fiftyone_docs&quot;def create_index():    client.recreate_collection(    collection_name=COLLECTION_NAME,    vectors_config = qmodels.VectorParams(            size=DIMENSION,            distance=METRIC,        )    )" id="code14-l1"><span class="lineCounter-0-0-4 prim -codedoc-line-counter">1<span class="-codedoc-line-link"><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span></span>import qdrant_client as qcimport qdrant_client.http.models as qmodelsclient = qc.QdrantClient(url="localhost")METRIC = qmodels.Distance.DOTDIMENSION = 1536COLLECTION_NAME = "fiftyone_docs"def create_index():    client.recreate_collection(    collection_name=COLLECTION_NAME,    vectors_config = qmodels.VectorParams(            size=DIMENSION,            distance=METRIC,        )    )</div><br></code></pre><p>I then created a vector for each subsection (text or code block):</p><pre class=""><code class="undefined -codedoc-code-snippet code-0-0-3" tabindex="0"><span class="wmbar-0-0-8"><span></span><span></span><span></span><span></span></span><div class="line-0-0-7  -codedoc-code-line" data-content="import uuiddef create_subsection_vector(    subsection_content,    section_anchor,    page_url,    doc_type    ):    vector = embed_text(subsection_content)    id = str(uuid.uuid1().int)[:32]    payload = {        &quot;text&quot;: subsection_content,        &quot;url&quot;: page_url,        &quot;section_anchor&quot;: section_anchor,        &quot;doc_type&quot;: doc_type,        &quot;block_type&quot;: block_type    }    return id, vector, payload" id="code15-l1"><span class="lineCounter-0-0-4 prim -codedoc-line-counter">1<span class="-codedoc-line-link"><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span></span>import uuiddef create_subsection_vector(    subsection_content,    section_anchor,    page_url,    doc_type    ):    vector = embed_text(subsection_content)    id = str(uuid.uuid1().int)[:32]    payload = {        "text": subsection_content,        "url": page_url,        "section_anchor": section_anchor,        "doc_type": doc_type,        "block_type": block_type    }    return id, vector, payload</div><br></code></pre><p>For each vector, you can provide additional context as part of the <a href="https://qdrant.tech/documentation/payload/">payload</a>. In this case, I included the URL (and anchor) where the result can be found, the <em>type</em> of document, so the user can specify if they want to search through all of the docs, or just certain types of docs, and the contents of the string which generated the embedding vector. I also added the block type (text or code), so if the user is looking for a code snippet, they can tailor their search to that purpose.</p><p>Then I added these vectors to the index, one page at a time:</p><pre class=""><code class="undefined -codedoc-code-snippet code-0-0-3" tabindex="0"><span class="wmbar-0-0-8"><span></span><span></span><span></span><span></span></span><div class="line-0-0-7  -codedoc-code-line" data-content="def add_doc_to_index(subsections, page_url, doc_type, block_type):    ids = []    vectors = []    payloads = []        for section_anchor, section_content in subsections.items():        for subsection in section_content:            id, vector, payload = create_subsection_vector(                subsection,                section_anchor,                page_url,                doc_type,                block_type            )            ids.append(id)            vectors.append(vector)            payloads.append(payload)        ## Add vectors to collection    client.upsert(        collection_name=COLLECTION_NAME,        points=qmodels.Batch(            ids = ids,            vectors=vectors,            payloads=payloads        ),    )" id="code16-l1"><span class="lineCounter-0-0-4 prim -codedoc-line-counter">1<span class="-codedoc-line-link"><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span></span>def add_doc_to_index(subsections, page_url, doc_type, block_type):    ids = []    vectors = []    payloads = []        for section_anchor, section_content in subsections.items():        for subsection in section_content:            id, vector, payload = create_subsection_vector(                subsection,                section_anchor,                page_url,                doc_type,                block_type            )            ids.append(id)            vectors.append(vector)            payloads.append(payload)        ## Add vectors to collection    client.upsert(        collection_name=COLLECTION_NAME,        points=qmodels.Batch(            ids = ids,            vectors=vectors,            payloads=payloads        ),    )</div><br></code></pre><h2 id="querying-the-index" class="heading-0-0-1"><span class="anchor-0-0-2" data-ignore-text=""><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span>Querying the index</h2><p>Once the index has been created, running a search on the indexed documents can be accomplished by embedding the query text with the same embedding model, and then searching the index for similar embedding vectors. With a Qdrant vector index, a basic query can be performed with the Qdrant client’s <code>search()</code> command.</p><p>To make my company’s docs searchable, I wanted to allow users to filter by section of the docs, as well as by the type of block that was encoded. In the parlance of vector search, filtering results while still ensuring that a predetermined number of results (specified by the <code>top_k</code> argument) will be returned is referred to as <em>pre-filtering</em>.</p><p>To achieve this, I wrote a programmatic filter:</p><pre class=""><code class="undefined -codedoc-code-snippet code-0-0-3" tabindex="0"><span class="wmbar-0-0-8"><span></span><span></span><span></span><span></span></span><div class="line-0-0-7  -codedoc-code-line" data-content="def _generate_query_filter(query, doc_types, block_types):    &quot;&quot;&quot;Generates a filter for the query.    Args:        query: A string containing the query.        doc_types: A list of document types to search.        block_types: A list of block types to search.    Returns:        A filter for the query.    &quot;&quot;&quot;    doc_types = _parse_doc_types(doc_types)    block_types = _parse_block_types(block_types)    _filter = models.Filter(        must=[            models.Filter(                should= [                    models.FieldCondition(                        key=&quot;doc_type&quot;,                        match=models.MatchValue(value=dt),                    )                for dt in doc_types                ],                    ),            models.Filter(                should= [                    models.FieldCondition(                        key=&quot;block_type&quot;,                        match=models.MatchValue(value=bt),                    )                for bt in block_types                ]              )        ]    )    return _filter" id="code17-l1"><span class="lineCounter-0-0-4 prim -codedoc-line-counter">1<span class="-codedoc-line-link"><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span></span>def _generate_query_filter(query, doc_types, block_types):    """Generates a filter for the query.    Args:        query: A string containing the query.        doc_types: A list of document types to search.        block_types: A list of block types to search.    Returns:        A filter for the query.    """    doc_types = _parse_doc_types(doc_types)    block_types = _parse_block_types(block_types)    _filter = models.Filter(        must=[            models.Filter(                should= [                    models.FieldCondition(                        key="doc_type",                        match=models.MatchValue(value=dt),                    )                for dt in doc_types                ],                    ),            models.Filter(                should= [                    models.FieldCondition(                        key="block_type",                        match=models.MatchValue(value=bt),                    )                for bt in block_types                ]              )        ]    )    return _filter</div><br></code></pre><p>The internal <code>_parse_doc_types()</code> and <code>_parse_block_types()</code> functions handle cases where the argument is string or list-valued, or is None.</p><p>Then I wrote a function <code>query_index()</code> that takes the user’s text query, pre-filters, searches the index, and extracts relevant information from the payload. The function returns a list of tuples of the form <code>(url, contents, score)</code>, where the score indicates how good of a match the result is to the query text.</p><pre class=""><code class="undefined -codedoc-code-snippet code-0-0-3" tabindex="0"><span class="wmbar-0-0-8"><span></span><span></span><span></span><span></span></span><div class="line-0-0-7  -codedoc-code-line" data-content="def query_index(query, top_k=10, doc_types=None, block_types=None):    vector = embed_text(query)    _filter = _generate_query_filter(query, doc_types, block_types)        results = CLIENT.search(        collection_name=COLLECTION_NAME,        query_vector=vector,        query_filter=_filter,        limit=top_k,        with_payload=True,        search_params=_search_params,    )    results = [        (            f&quot;{res.payload['url']}#{res.payload['section_anchor']}&quot;,            res.payload[&quot;text&quot;],            res.score,        )        for res in results    ]    return results" id="code18-l1"><span class="lineCounter-0-0-4 prim -codedoc-line-counter">1<span class="-codedoc-line-link"><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span></span>def query_index(query, top_k=10, doc_types=None, block_types=None):    vector = embed_text(query)    _filter = _generate_query_filter(query, doc_types, block_types)        results = CLIENT.search(        collection_name=COLLECTION_NAME,        query_vector=vector,        query_filter=_filter,        limit=top_k,        with_payload=True,        search_params=_search_params,    )    results = [        (            f"{res.payload['url']}#{res.payload['section_anchor']}",            res.payload["text"],            res.score,        )        for res in results    ]    return results</div><br></code></pre><h2 id="writing-the-search-wrapper" class="heading-0-0-1"><span class="anchor-0-0-2" data-ignore-text=""><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span>Writing the search wrapper</h2><p>The final step was providing a clean interface for the user to semantically search against these “vectorized” docs.</p><p>I wrote a function <code>print_results()</code>, which takes the query, results from <code>query_index()</code>, and a <code>score</code> argument (whether or not to print the similarity score), and prints the results in an easy to interpret way. I used the <a href="https://rich.readthedocs.io/en/stable/introduction.html">rich</a> Python package to format hyperlinks in the terminal so that when working in a terminal that supports hyperlinks, clicking on the hyperlink will open the page in your default browser. I also used <a href="https://docs.python.org/3/library/webbrowser.html">webbrowser</a> to automatically open the link for the top result, if desired.</p><p><img src="https://miro.medium.com/v2/resize:fit:700/1*l05snNlGxtVd4LIFLG_deg.gif" alt=""></p><p>Display search results with rich hyperlinks. Image courtesy of author.</p><p>For Python-based searches, I created a class <code>FiftyOneDocsSearch</code> to encapsulate the document search behavior, so that once a <code>FiftyOneDocsSearch</code> object has been instantiated (potentially with default settings for search arguments):</p><pre class=""><code class="undefined -codedoc-code-snippet code-0-0-3" tabindex="0"><span class="wmbar-0-0-8"><span></span><span></span><span></span><span></span></span><div class="line-0-0-7  -codedoc-code-line" data-content="from fiftyone.docs_search import FiftyOneDocsSearchfosearch = FiftyOneDocsSearch(open_url=False, top_k=3, score=True)" id="code19-l1"><span class="lineCounter-0-0-4 prim -codedoc-line-counter">1<span class="-codedoc-line-link"><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span></span>from fiftyone.docs_search import FiftyOneDocsSearchfosearch = FiftyOneDocsSearch(open_url=False, top_k=3, score=True)</div><br></code></pre><p>You can search within Python by calling this object. To query the docs for “How to load a dataset”, for instance, you just need to run:</p><pre class=""><code class="undefined -codedoc-code-snippet code-0-0-3" tabindex="0"><span class="wmbar-0-0-8"><span></span><span></span><span></span><span></span></span><div class="line-0-0-7  -codedoc-code-line" data-content="fosearch(“How to load a dataset”)" id="code20-l1"><span class="lineCounter-0-0-4 prim -codedoc-line-counter">1<span class="-codedoc-line-link"><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span></span>fosearch(“How to load a dataset”)</div><br></code></pre><p><img src="https://miro.medium.com/v2/resize:fit:700/1*vp7HRYNYuiZSSbgqDj9aBw.gif" alt=""></p><p>Semantically search your company’s docs within a Python process. Image courtesy of author.</p><p>I also used <a href="https://docs.python.org/3/library/argparse.html">argparse</a> to make this docs search functionality available via the command line. When the package is installed, the docs are CLI searchable with:</p><pre class=""><code class="undefined -codedoc-code-snippet code-0-0-3" tabindex="0"><span class="wmbar-0-0-8"><span></span><span></span><span></span><span></span></span><div class="line-0-0-7  -codedoc-code-line" data-content="fiftyone-docs-search query &quot;<my-query>&quot; <args " id="code21-l1"><span class="lineCounter-0-0-4 prim -codedoc-line-counter">1<span class="-codedoc-line-link"><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span></span>fiftyone-docs-search query "<my-query>" </my-query></div><br></code></pre><p>Just for fun, because <code>fiftyone-docs-search query</code> is a bit cumbersome, I added an alias to my <code>.zsrch</code> file:</p><pre class=""><code class="undefined -codedoc-code-snippet code-0-0-3" tabindex="0"><span class="wmbar-0-0-8"><span></span><span></span><span></span><span></span></span><div class="line-0-0-7  -codedoc-code-line" data-content="alias fosearch='fiftyone-docs-search query'" id="code22-l1"><span class="lineCounter-0-0-4 prim -codedoc-line-counter">1<span class="-codedoc-line-link"><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span></span>alias fosearch='fiftyone-docs-search query'</div><br></code></pre><p>With this alias, the docs are searchable from the command line with:</p><pre class=""><code class="undefined -codedoc-code-snippet code-0-0-3" tabindex="0"><span class="wmbar-0-0-8"><span></span><span></span><span></span><span></span></span><div class="line-0-0-7  -codedoc-code-line" data-content="fosearch &quot;<my-query>&quot; args" id="code23-l1"><span class="lineCounter-0-0-4 prim -codedoc-line-counter">1<span class="-codedoc-line-link"><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span></span>fosearch "<my-query>" args</my-query></div><br></code></pre><h2 id="conclusion" class="heading-0-0-1"><span class="anchor-0-0-2" data-ignore-text=""><span class="icon-font" data-ignore-text="" style="vertical-align: sub">link</span></span>Conclusion</h2><p>Coming into this, I already fashioned myself a power user of my company’s open source Python library, FiftyOne. I had written many of the docs, and I had used (and continue to use) the library on a daily basis. But the process of turning our docs into a searchable database forced me to understand our docs on an even deeper level. It’s always great when you’re building something for others, and it ends up helping you as well!</p><p>Here’s what I learned:</p><ul><li><strong>Sphinx RST is cumbersome</strong>: it makes beautiful docs, but it is a bit of a pain to parse</li><li><strong>Don’t go crazy with preprocessing:</strong> OpenAI’s text-embeddings-ada-002 model is great at understanding the meaning behind a text string, even if it has slightly atypical formatting. Gone are the days of stemming and painstakingly removing stop words and miscellaneous characters.</li><li><strong>Small semantically meaningful snippets are best</strong>: break your documents up into the smallest possible meaningful segments, and retain context. For longer pieces of text, it is more likely that overlap between a search query and a part of the text in your index will be obscured by less relevant text in the segment. If you break the document up too small, you run the risk that many entries in the index will contain very little semantic information.</li><li><strong>Vector search is powerful</strong>: with minimal lift, and without any fine-tuning, I was able to dramatically enhance the searchability of our docs. From initial estimates, it appears that this improved docs search is more than twice as likely to return relevant results than the old keyword search approach. Furthermore, the semantic nature of this vector search approach means that users can now search with arbitrarily phrased, arbitrarily complex queries, and are guaranteed to get the specified number of results.</li></ul><p>If you find yourself (or others) constantly digging or sifting through treasure troves of documentation for specific kernels of information, I encourage you to adapt this process for your own use case. You can modify this to work for your personal documents, or your company’s archives. And if you do, I guarantee you’ll walk away from the experience seeing your documents in a new light!</p><p>Here are a few ways you could extend this for your own docs!</p><ul><li><a href="https://www.pinecone.io/learn/hybrid-search-intro/">Hybrid search</a>: combine vector search with traditional keyword search</li><li>Go global: Use <a href="https://cloud.qdrant.io/">Qdrant Cloud</a> to store and query the collection in the cloud</li><li>Incorporate web data: use <a href="https://pypi.org/project/requests/">requests</a> to download HTML directly from the web</li><li>Automate updates: use <a href="https://docs.github.com/en/actions">Github Actions</a> to trigger recomputation of embeddings whenever the underlying docs change</li><li>Embed: wrap this in a Javascript element and drop it in as a replacement for a traditional search bar</li></ul><p>All code used to build the package is open source, and can be found in the <a href="https://github.com/voxel51/fiftyone-docs-search">voxel51/fiftyone-docs-search</a> repo.</p><div class="contentnav-0-0-17" data-no-search=""><a href="#and-how-you-can-do-the-same-with-your-docs" class="h2" data-content-highlight="and-how-you-can-do-the-same-with-your-docs">And how you can do the same with your docs</a><a href="#converting-the-docs-to-a-unified-format" class="h2" data-content-highlight="converting-the-docs-to-a-unified-format">Converting the docs to a unified format</a><a href="#rst" class="h2" data-content-highlight="rst">RST</a><a href="#jupyter" class="h2" data-content-highlight="jupyter">Jupyter</a><a href="#html" class="h2" data-content-highlight="html">HTML</a><a href="#markdown" class="h2" data-content-highlight="markdown">Markdown</a><a href="#note-on-langchain" class="h2" data-content-highlight="note-on-langchain">Note on LangChain</a><a href="#processing-the-documents" class="h2" data-content-highlight="processing-the-documents">Processing the documents</a><a href="#cleaning" class="h2" data-content-highlight="cleaning">Cleaning</a><a href="#splitting-documents-into-semantic-blocks" class="h2" data-content-highlight="splitting-documents-into-semantic-blocks">Splitting documents into semantic blocks</a><a href="#embedding-text-and-code-blocks-with-openai" class="h2" data-content-highlight="embedding-text-and-code-blocks-with-openai">Embedding text and code blocks with OpenAI</a><a href="#creating-a-qdrant-vector-index" class="h2" data-content-highlight="creating-a-qdrant-vector-index">Creating a Qdrant vector index</a><a href="#querying-the-index" class="h2" data-content-highlight="querying-the-index">Querying the index</a><a href="#writing-the-search-wrapper" class="h2" data-content-highlight="writing-the-search-wrapper">Writing the search wrapper</a><a href="#conclusion" class="h2" data-content-highlight="conclusion">Conclusion</a></div></div><div id="-codedoc-toc" class="toc-0-0-14"><div class="content-0-0-15"><div class="heading-0-0-9">Index</div><p><a href="/codedoc/">Home</a>
<a href="/codedoc/README">Index</a>
<a href="/codedoc/docs/Kostwein">Kostwein</a></p><div class="collapse-0-0-10 "><script id="hFqISjRVce">(function(){function load(){if (window.__sdh_transport){window.__sdh_transport("hFqISjRVce", "yAdNJkOJGbj52dvfV+HpdQ==", {});} }; if (document.readyState == 'complete') load(); else window.addEventListener('load', load); window.setImmediate = window.setImmediate || function(f){setTimeout(f, 0)}; })()</script><div class="label" onclick="this.parentElement.classList.toggle('open')"><span class="text">PSModulesHelp</span><span class="icon-font closed">chevron_right</span></div><div class="content"><p><a href="/codedoc/docs/PSModulesHelp/ModuleDoku">PS Modules Help</a></p><hr></div></div><div class="collapse-0-0-10 "><script id="sJGSCdeNxq">(function(){function load(){if (window.__sdh_transport){window.__sdh_transport("sJGSCdeNxq", "yAdNJkOJGbj52dvfV+HpdQ==", {});} }; if (document.readyState == 'complete') load(); else window.addEventListener('load', load); window.setImmediate = window.setImmediate || function(f){setTimeout(f, 0)}; })()</script><div class="label" onclick="this.parentElement.classList.toggle('open')"><span class="text">KnowledgeBase</span><span class="icon-font closed">chevron_right</span></div><div class="content"><blockquote><p><a href="/codedoc/docs/Knowledge/PowerShell/Index">PowerShell</a></p></blockquote></div></div><div class="collapse-0-0-10 "><script id="fWDxAIrbPk">(function(){function load(){if (window.__sdh_transport){window.__sdh_transport("fWDxAIrbPk", "yAdNJkOJGbj52dvfV+HpdQ==", {});} }; if (document.readyState == 'complete') load(); else window.addEventListener('load', load); window.setImmediate = window.setImmediate || function(f){setTimeout(f, 0)}; })()</script><div class="label" onclick="this.parentElement.classList.toggle('open')"><span class="text">Links</span><span class="icon-font closed">chevron_right</span></div><div class="content"><blockquote><p><a href="/codedoc/docs/Links/LinksWiki">Index</a></p></blockquote></div></div><div class="collapse-0-0-10 "><script id="RGvJXRgGWl">(function(){function load(){if (window.__sdh_transport){window.__sdh_transport("RGvJXRgGWl", "yAdNJkOJGbj52dvfV+HpdQ==", {});} }; if (document.readyState == 'complete') load(); else window.addEventListener('load', load); window.setImmediate = window.setImmediate || function(f){setTimeout(f, 0)}; })()</script><div class="label" onclick="this.parentElement.classList.toggle('open')"><span class="text">Veeam</span><span class="icon-font closed">chevron_right</span></div><div class="content"><blockquote><p><a href="/codedoc/docs/Knowledge/Veeam/Best%20Practices/index">Best Practices</a></p></blockquote></div></div><p><a href="/codedoc/docs/cheat-sheet">Markdown Cheat Sheet</a>
<a href="/codedoc/docs/code-features">Code Features</a></p><p><br><br></p><p>To add links to your other documents, simply
modify contents of <code>docs/md/_toc.md</code>.</p></div><div class="search-0-0-16"><script id="UTsHSYMaeS">(function(){function load(){if (window.__sdh_transport){window.__sdh_transport("UTsHSYMaeS", "EKtVWhWp+AfK3O64A4+bOg==", {"repo":"codedoc","user":"In-Pro-Org","root":"docs/md","pick":"\\.md$","drop":"(^_)|(\\/_)"});} }; if (document.readyState == 'complete') load(); else window.addEventListener('load', load); window.setImmediate = window.setImmediate || function(f){setTimeout(f, 0)}; })()</script></div></div><div class="footer-0-0-13"><div class="left"><script id="_xWDQBhaMZ">(function(){function load(){if (window.__sdh_transport){window.__sdh_transport("_xWDQBhaMZ", "wCsMx1XMyC4jNi3FxvjU4g==", {});} }; if (document.readyState == 'complete') load(); else window.addEventListener('load', load); window.setImmediate = window.setImmediate || function(f){setTimeout(f, 0)}; })()</script></div><div class="main"><div class="inside"><a href="https://github.com/In-Pro-Org/codedoc/" target="_blank">GitHub</a></div></div><div class="right"><script id="lhgTFYwSZf">(function(){function load(){if (window.__sdh_transport){window.__sdh_transport("lhgTFYwSZf", "6W59GcSTLBVXRr/Nl/rTkw==", {});} }; if (document.readyState == 'complete') load(); else window.addEventListener('load', load); window.setImmediate = window.setImmediate || function(f){setTimeout(f, 0)}; })()</script></div></div><script id="BiMWrJDKGP">(function(){function load(){if (window.__sdh_transport){window.__sdh_transport("BiMWrJDKGP", "zKXJ5zf13oJGCwAAI3JIIA==", {"namespace":"/codedoc"});} }; if (document.readyState == 'complete') load(); else window.addEventListener('load', load); window.setImmediate = window.setImmediate || function(f){setTimeout(f, 0)}; })()</script></body></html>